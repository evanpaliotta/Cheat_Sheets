{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Importing Libraries and Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns #statistical data visualization\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Creating the File Path\n",
    "csvpath = Path(\"file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Reading a CSV\n",
    "df = pd.read_csv(csvpath)#additional specifiers (csv_path, parse_dates=True, index_col=\"Date\", infer_datetime_format=True)\n",
    "\n",
    "#Without a Header\n",
    "df = pd.read_csv(csvpath, header=None)\n",
    "\n",
    "#Google Finance Data Retreival\n",
    "=GOOGLEFINANCE(ticker, [attribute], [start_date], [num_days|end_date], [interval])\n",
    "\n",
    "#Concatinating Files\n",
    "path1 = Path('file1')\n",
    "path2 = Path('file2')\n",
    "path3 = Path('file3')\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)\n",
    "df3 = pd.read_csv(path3)\n",
    "concatinated_df = pd.concat([df1,df2,df3], axis='columns or rows or 0,1', join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Looking at the Data\n",
    "#-----Think of () as specifiers-----\n",
    "\n",
    "#Looking at the Beginning/End Values\n",
    "df.head()\n",
    "df.tail()\n",
    "\n",
    "#Generate Summary Statistics.....option to (include='all') or specify inclusion\n",
    "df.describe()\n",
    "\n",
    "#Reading Columns\n",
    "df.columns\n",
    "\n",
    "#Generate a Random Sample\n",
    "df.sample()\n",
    "\n",
    "#Identify Data Types\n",
    "df.dtypes\n",
    "\n",
    "#Counting\n",
    "df.count()\n",
    "\n",
    "#Assigning Ranks to Entries\n",
    "df.rank()\n",
    "\n",
    "#Identifying frequency values\n",
    "df['column'].value_counts()\n",
    "\n",
    "#Sorting\n",
    "df.sort_index()\n",
    "df.sort_values()\n",
    "\n",
    "#Checking for null\n",
    "df.isnull()\n",
    "\n",
    "#Determining number of nulls\n",
    "df.isnull().sum()\n",
    "\n",
    "#Drop Nulls\n",
    "df.dropna()\n",
    "\n",
    "# Checking duplicates\n",
    "df.duplicated()\n",
    "\n",
    "# Checking duplicates for specific field\n",
    "csv_data['column'].duplicated()\n",
    "\n",
    "#Calculating Correlation\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Working with Columns/Rows\n",
    "\n",
    "#Rewriting Columns\n",
    "columns = [\"Col1\", \"Col2\", \"Col3\"]#can re-write by changing the order\n",
    "df.columns = columns\n",
    "df.rename(columns={'old_variable1':'new_variable1','old_variable2':'new_variable2'})\n",
    "\n",
    "#Dropping Columns\n",
    "df.drop(columns=['Col1', 'COl2'])#specify inplace=True\n",
    "\n",
    "#Creating Columns\n",
    "df[\"new_column_name\"] = df[\"manipulated_column\"] / 1000\n",
    "\n",
    "#Order Rows by Values of Columns\n",
    "df.sort_values('Col')#low to high\n",
    "df.sort_values('Col', ascending=False)#high to low\n",
    "\n",
    "#Splitting Columns\n",
    "new_variable=df[\"column_to_split\"].str.split(\" \", expand=True)\n",
    "\n",
    "#Indexing \n",
    "df.iloc[row specifications: column specifications]\n",
    "df.loc['column']#or other specification\n",
    "df = df.set_index('index')\n",
    "\n",
    "#Multi-Indexing\n",
    "# Set multi-index by grouping\n",
    "df = df.groupby([df.index.year, df.index.month])#.first\n",
    "\n",
    "#Extract Rows that meet Logical Criteria\n",
    "df[df.specifier]#ex. Length >7\n",
    "\n",
    "#Grouping Data\n",
    "df.groupby()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Manipulating Data\n",
    "\n",
    "#Cleanse nulls from DataFrame by filling na\n",
    "df['column'] = df['column'].fillna(\"Unknown\")\n",
    "\n",
    "#Cleansing duplicates\n",
    "df.drop_duplicates()\n",
    "\n",
    "# Converting Column to Specific Type\n",
    "df['column'] = df['column'].astype('type')\n",
    "\n",
    "# Filter rows based on a column value conditional\n",
    "df.loc[df['column'] == 'Conditional']\n",
    "\n",
    "#Fix Date\n",
    "df_fixed = df.copy()\n",
    "df_fixed.index = df.index.to_series().dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Visualization\n",
    "\n",
    "#Plotting Data\n",
    "df.plot() #spefify (kind='bar', title='', figsize=()etc...)\n",
    "\n",
    "#Rolling Statistics\n",
    "df.rolling() #specify (window=7).mean()\n",
    "\n",
    "# Plot multiple things on one chart\n",
    "variable = df.plot(figsize=(number,number))\n",
    "# Overlay SMA20, SMA50, and SMA100 on the same figure\n",
    "sma_20.plot(ax=variable)\n",
    "sma_50.plot(ax=variable)\n",
    "sma_100.plot(ax=variable)\n",
    "\n",
    "#Setting the legend\n",
    "variable.legend([\"First\", \"Second\", \"Third\"])\n",
    "\n",
    "#Seaborn library scatterplot\n",
    "sns.lmplot(x='axis specifier', y='axis speifier', data=df, aspect=1.5, fit_reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Relevant Calculations\n",
    "\n",
    "#Summary Functions\n",
    "df.sum()\n",
    "df.count()\n",
    "df.min()\n",
    "df.max()\n",
    "df.median()\n",
    "df.mean()\n",
    "df.pct_change()\n",
    "df.var()#variance\n",
    "df.std()#standard deviation\n",
    "\n",
    "#Volatility\n",
    "volatility = all_returns.std() * np.sqrt(252) #252 is the yearly\n",
    "\n",
    "#Beta\n",
    "stock_covariance = daily_returns['Stock'].cov(daily_returns['S&P 500'])\n",
    "stock_variance = daily_returns['S&P 500'].var()\n",
    "stock_beta = stock_covariance / stock_variance\n",
    "\n",
    "#Sharpe Ratio\n",
    "sharpe_ratios = (all_portfolios_returns.mean() * 252) / (all_portfolios_returns.std() * np.sqrt(252))\n",
    "\n",
    "#Calculating returns\n",
    "stock1_weight = 0.5\n",
    "stock2_weight = 0.5\n",
    "\n",
    "portfolio_returns = stock1_weight * all_returns[\"stock1\"] + stock2_weight * all_returns[\"stock2\"]\n",
    "\n",
    "#Shortcut for calculating returns\n",
    "weights = [0.5, 0.5]\n",
    "portfolio_returns = all_returns.dot(weights)\n",
    "\n",
    "#Cumulative Returns\n",
    "#set initial_investment variable\n",
    "cumulative_returns = (1 + portfolio_returns).cumprod()-1\n",
    "(initial_investment * cumulative_returns)#.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
